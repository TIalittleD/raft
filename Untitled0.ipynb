{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCqFlb/kkDB+T7UHEhbNJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIalittleD/raft/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "4VM03zv-tAHX",
        "outputId": "7fb0e8ee-2eb6-401f-dbf6-71e89b1e7d95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62446a97-9fe7-497c-8cff-f69b2235601d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62446a97-9fe7-497c-8cff-f69b2235601d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Font.zip to Font.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "# 假设上传的文件名为 uploaded.zip\n",
        "file_path = 'Font.zip'\n",
        "\n",
        "# 解压缩文件\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.getcwd())\n"
      ],
      "metadata": {
        "id": "39tQd4Kp8DF5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0sDZ_k6iscVI"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageDraw\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# %% 要生成的文本\n",
        "label_dict = {0: '0', 1: '1', 2: '2', 3: '3',\n",
        "              4: '4', 5: '5', 6: '6', 7: '7',\n",
        "              8: '8', 9: '9', 10: '=', 11: '+',\n",
        "              12: '-',13: '×', 14: '÷'}\n",
        "\n",
        "# 文本对应的文件夹，给每一个分类建一个文件\n",
        "for value, char in label_dict.items():\n",
        "    train_images_dir = \"dataset\" + \"/\" + str(value)\n",
        "    if os.path.isdir(train_images_dir):\n",
        "        shutil.rmtree(train_images_dir)\n",
        "    os.makedirs(train_images_dir)\n",
        "\n",
        "\n",
        "#\n",
        "def get_square_img(image):\n",
        "    x, y, w, h = cv2.boundingRect(image)\n",
        "    image = image[y:y + h, x:x + w]\n",
        "\n",
        "    max_size = 18\n",
        "    max_size_and_border = 24\n",
        "\n",
        "    if w > max_size or h > max_size:  # 有超过宽高的情况\n",
        "        if w >= h:  # 宽比高长，压缩宽\n",
        "            times = max_size / w\n",
        "            w = max_size\n",
        "            h = int(h * times)\n",
        "        else:  # 高比宽长，压缩高\n",
        "            times = max_size / h\n",
        "            h = max_size\n",
        "            w = int(w * times)\n",
        "        # 保存图片大小\n",
        "        image = cv2.resize(image, (w, h))\n",
        "\n",
        "    xw = image.shape[0]\n",
        "    xh = image.shape[1]\n",
        "\n",
        "    xwLeftNum = int((max_size_and_border - xw) / 2)\n",
        "    xwRightNum = (max_size_and_border - xw) - xwLeftNum\n",
        "\n",
        "    xhLeftNum = int((max_size_and_border - xh) / 2)\n",
        "    xhRightNum = (max_size_and_border - xh) - xhLeftNum\n",
        "\n",
        "    img_large = np.pad(image, ((xwLeftNum, xwRightNum), (xhLeftNum, xhRightNum)), 'constant', constant_values=(0, 0))\n",
        "\n",
        "    return img_large\n",
        "\n",
        "\n",
        "# %% 生成图片\n",
        "def makeImage(label_dict, font_path, width=24, height=24, rotate=0):\n",
        "    # 从字典中取出键值对\n",
        "    for value, char in label_dict.items():\n",
        "        # 创建一个黑色背景的图片，大小是24*24\n",
        "        img = Image.new(\"RGB\", (width, height), \"black\")\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        scale = 1.0\n",
        "        # 字符扩大字号倍数\n",
        "        if value in [12]:  # '-'\n",
        "            scale = 1.3\n",
        "        if value in [12, 14]:  # '-' '÷'\n",
        "            scale = 1.2\n",
        "        if value in [10, 11, 13]:  # '=' '+' '×'\n",
        "            scale = 1.1\n",
        "        font = ImageFont.truetype(font_path, int(width * scale))\n",
        "        # 获取字体的宽高\n",
        "        font_bbox = draw.textbbox((0, 0), char, font=font)\n",
        "        font_width = font_bbox[2] - font_bbox[0]\n",
        "        font_height = font_bbox[3] - font_bbox[1]\n",
        "        # 计算字体绘制的x,y坐标，主要是让文字画在图标中心\n",
        "        x = (width - font_width - font.getbbox(char)[0]) / 2\n",
        "        y = (height - font_height - font.getbbox(char)[1]) / 2\n",
        "        # 绘制图片，在那里画，画啥，什么颜色，什么字体\n",
        "        draw.text((x, y), char, (255, 255, 255), font)\n",
        "        # 设置图片倾斜角度\n",
        "        if rotate != 0:\n",
        "            img = img.rotate(rotate)\n",
        "\n",
        "        img_arr = np.array(img)\n",
        "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
        "        img_arr = get_square_img(img_arr)\n",
        "\n",
        "        img = Image.fromarray(img_arr)\n",
        "        # 命名文件保存，命名规则：dataset/编号/img-编号_r-选择角度_时间戳.png\n",
        "        time_value = int(round(time.time() * 1000))\n",
        "        img_path = \"dataset/{}/img-{}_r-{}_{}.png\".format(value, value, rotate, time_value)\n",
        "        img.save(img_path)\n",
        "\n",
        "\n",
        "# %% 存放字体的路径\n",
        "font_dir = \"Font\"\n",
        "for font_name in os.listdir(font_dir):\n",
        "    # 把每种字体都取出来，每种字体都生成一批图片\n",
        "    path_font_file = os.path.join(font_dir, font_name)\n",
        "\n",
        "    # makeImage(label_dict, path_font_file)\n",
        "    # 倾斜角度从-10到10度，每个角度都生成一批图片\n",
        "    for k in range(-10, 10):\n",
        "        # 每个字符都生成图片\n",
        "        makeImage(label_dict, path_font_file, rotate=k)\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def create_custom_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Rescaling(1. / 255),\n",
        "        layers.Conv2D(24, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(96, activation='relu'),\n",
        "        layers.Dense(15)\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def prepare_dataset(data_dir, img_width, img_height, batch_size, validation_split=0.2, seed=123):\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=validation_split,\n",
        "        subset='training',\n",
        "        seed=seed,\n",
        "        color_mode=\"grayscale\",\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=validation_split,\n",
        "        subset=\"validation\",\n",
        "        seed=seed,\n",
        "        color_mode=\"grayscale\",\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # 数据集预处理\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return train_ds, val_ds\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, train_ds, val_ds, epochs, checkpoint_path):\n",
        "    # 创建一个保存模型权重的回调函数\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                  save_weights_only=True,\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[cp_callback])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_dir = pathlib.Path('dataset')\n",
        "    img_width, img_height = 24, 24\n",
        "    batch_size = 64\n",
        "    num_classes = 15\n",
        "    input_shape = (img_height, img_width, 1)  # 使用灰度图像作为输入\n",
        "    epochs = 10\n",
        "    checkpoint_path = \"checkpoint/char_checkpoint.weights.h5\"\n",
        "\n",
        "    train_ds, val_ds = prepare_dataset(data_dir, img_width, img_height, batch_size)\n",
        "    model = create_custom_model(input_shape, num_classes)\n",
        "    train_model(model, train_ds, val_ds, epochs, checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH2PN9UC8s24",
        "outputId": "45bd980f-cd58-447e-f364-ce52c8bf36c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 106500 files belonging to 15 classes.\n",
            "Using 85200 files for training.\n",
            "Found 106500 files belonging to 15 classes.\n",
            "Using 21300 files for validation.\n",
            "Epoch 1/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.9053\n",
            "Epoch 1: val_loss improved from inf to 0.15688, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 73s 50ms/step - loss: 0.3351 - accuracy: 0.9054 - val_loss: 0.1569 - val_accuracy: 0.9534\n",
            "Epoch 2/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9535\n",
            "Epoch 2: val_loss improved from 0.15688 to 0.13965, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 61s 46ms/step - loss: 0.1508 - accuracy: 0.9535 - val_loss: 0.1396 - val_accuracy: 0.9565\n",
            "Epoch 3/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9587\n",
            "Epoch 3: val_loss improved from 0.13965 to 0.11807, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 63s 47ms/step - loss: 0.1269 - accuracy: 0.9587 - val_loss: 0.1181 - val_accuracy: 0.9593\n",
            "Epoch 4/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9600\n",
            "Epoch 4: val_loss improved from 0.11807 to 0.11022, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 61s 46ms/step - loss: 0.1159 - accuracy: 0.9600 - val_loss: 0.1102 - val_accuracy: 0.9611\n",
            "Epoch 5/10\n",
            "1332/1332 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9618\n",
            "Epoch 5: val_loss improved from 0.11022 to 0.10486, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 62s 47ms/step - loss: 0.1077 - accuracy: 0.9618 - val_loss: 0.1049 - val_accuracy: 0.9615\n",
            "Epoch 6/10\n",
            "1332/1332 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9625\n",
            "Epoch 6: val_loss improved from 0.10486 to 0.10483, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 64s 48ms/step - loss: 0.1037 - accuracy: 0.9625 - val_loss: 0.1048 - val_accuracy: 0.9605\n",
            "Epoch 7/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9633\n",
            "Epoch 7: val_loss improved from 0.10483 to 0.09792, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 66s 49ms/step - loss: 0.0996 - accuracy: 0.9633 - val_loss: 0.0979 - val_accuracy: 0.9620\n",
            "Epoch 8/10\n",
            "1332/1332 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9631\n",
            "Epoch 8: val_loss did not improve from 0.09792\n",
            "1332/1332 [==============================] - 62s 47ms/step - loss: 0.0970 - accuracy: 0.9631 - val_loss: 0.0986 - val_accuracy: 0.9615\n",
            "Epoch 9/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9640\n",
            "Epoch 9: val_loss improved from 0.09792 to 0.09391, saving model to checkpoint/char_checkpoint.weights.h5\n",
            "1332/1332 [==============================] - 63s 47ms/step - loss: 0.0947 - accuracy: 0.9640 - val_loss: 0.0939 - val_accuracy: 0.9635\n",
            "Epoch 10/10\n",
            "1331/1332 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9646\n",
            "Epoch 10: val_loss did not improve from 0.09391\n",
            "1332/1332 [==============================] - 62s 47ms/step - loss: 0.0937 - accuracy: 0.9646 - val_loss: 0.0959 - val_accuracy: 0.9621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "from numpy.core.records import array\n",
        "from numpy.core.shape_base import block\n",
        "import time\n",
        "from collections import Counter\n",
        "import modle1\n",
        "\n",
        "\n",
        "# %%\n",
        "# 整幅图片的Y轴投影\n",
        "def img_y_shadow(img_b):\n",
        "    ### 计算投影 ###\n",
        "    (h, w) = img_b.shape\n",
        "    # 初始化一个跟图像高一样长度的数组，用于记录每一行的黑点个数\n",
        "    a = [0 for z in range(0, h)]\n",
        "    # 遍历每一列，记录下这一列包含多少有效像素点\n",
        "    for i in range(0, h):\n",
        "        for j in range(0, w):\n",
        "            if img_b[i, j] == 255:\n",
        "                a[i] += 1\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "# 图片获取文字块，传入投影列表，返回标记的数组区域坐标[[左，上，右，下]]\n",
        "def img2rows(a, w, h):\n",
        "    ### 根据投影切分图块 ###\n",
        "    inLine = False  # 是否已经开始切分\n",
        "    start = 0  # 某次切分的起始索引\n",
        "    mark_boxs = []\n",
        "    for i in range(0, len(a)):\n",
        "        if inLine == False and a[i] > 10:\n",
        "            inLine = True\n",
        "            start = i\n",
        "        # 记录这次选中的区域[左，上，右，下]，上下就是图片，左右是start到当前\n",
        "        elif i - start > 5 and a[i] < 10 and inLine:\n",
        "            inLine = False\n",
        "            if i - start > 10:\n",
        "                top = max(start - 1, 0)\n",
        "                bottom = min(h, i + 1)\n",
        "                box = [0, top, w, bottom]\n",
        "                mark_boxs.append(box)\n",
        "\n",
        "    return mark_boxs\n",
        "\n",
        "\n",
        "# 一行图片的X轴投影\n",
        "def img_x_shadow(img_b):\n",
        "    ### 计算投影 ###\n",
        "    (h, w) = img_b.shape\n",
        "    # 初始化一个跟图像宽一样长度的数组，用于记录每一列的像素数量\n",
        "    a = [0 for z in range(0, w)]\n",
        "    # 遍历每一列，记录下这一列包含多少有效像素点\n",
        "    for i in range(0, w):\n",
        "        for j in range(0, h):\n",
        "            if img_b[j, i] == 255:\n",
        "                a[i] += 1\n",
        "    return a\n",
        "\n",
        "\n",
        "# 图片获取文字块，传入图片路径，返回标记的数组区域坐标[[左，上，右，下]]\n",
        "def row2blocks(a, w, h):\n",
        "    ### 根据投影切分图块 ###\n",
        "    inLine = False  # 是否已经开始切分\n",
        "    start = 0  # 某次切分的起始索引\n",
        "    block_mark_boxs = []  # 切分的矩形区域坐标[左，上，右，下]\n",
        "\n",
        "    for i in range(0, len(a)):\n",
        "        # 如果还没有开始切，并且这列有效像素超过2个\n",
        "        if inLine == False and a[i] > 2:\n",
        "            inLine = True  # 标记为现在开始切块\n",
        "            start = i  # 标记这次切块的位置索引\n",
        "        # 如果在切，并且已经超过10个，并且这次低于2个有效像素，说明遇到空白了\n",
        "        elif i - start > 10 and a[i] < 2 and inLine:\n",
        "            inLine = False  # 标记不切了\n",
        "            # 记录这次选中的区域[左，上，右，下]，上下就是图片，左右是start到当前\n",
        "            left = max(start - 1, 0)\n",
        "            right = min(w, i + 1)\n",
        "            box = [left, 0, right, h]\n",
        "            block_mark_boxs.append(box)\n",
        "\n",
        "    return block_mark_boxs\n",
        "\n",
        "\n",
        "# 图片获取文字块，传入图片路径，返回标记的数组区域坐标[[左，上，右，下]]\n",
        "def block2chars(a, w, h, row_top, block_left):\n",
        "    ### 根据投影切分图块 ###\n",
        "    inLine = False  # 是否已经开始切分\n",
        "    start = 0  # 某次切分的起始索引\n",
        "    char_mark_boxs = []  # 切分的矩形区域坐标[左，上，右，下]\n",
        "    abs_char_mark_boxs = []  # 切分的矩形区域坐标[左，上，右，下]\n",
        "\n",
        "    for i in range(0, len(a)):\n",
        "        # 如果还没有开始切，并且这列有效像素超过1个\n",
        "        if inLine == False and a[i] > 0:\n",
        "            inLine = True  # 标记为现在开始切块\n",
        "            start = i  # 标记这次切块的位置索引\n",
        "        # 如果在切，并且已经超过5个，并且这次低于2个有效像素，说明遇到空白了\n",
        "        elif i - start > 5 and a[i] < 1 and inLine:\n",
        "            inLine = False  # 标记不切了\n",
        "            # 记录这次选中的区域[左，上，右，下]，上下就是图片，左右是start到当前\n",
        "            left = max(start - 1, 0)\n",
        "            right = min(w, i + 1)\n",
        "            box = [left, 0, right, h]\n",
        "            char_mark_boxs.append(box)\n",
        "            ads_box = [block_left + left, row_top, block_left + right, row_top + h]\n",
        "            abs_char_mark_boxs.append(ads_box)\n",
        "\n",
        "    return char_mark_boxs, abs_char_mark_boxs\n",
        "\n",
        "\n",
        "# 裁剪图片\n",
        "def cut_img(img, mark_boxs, is_square=False):\n",
        "    img_items = []\n",
        "    for i in range(0, len(mark_boxs)):\n",
        "        img_org = img.copy()\n",
        "        box = mark_boxs[i]\n",
        "        img_item = img_org[box[1]:box[3], box[0]:box[2]]\n",
        "\n",
        "        if is_square:  # 是否转化为方形\n",
        "            img_item = get_square_img(img_item)\n",
        "        img_items.append(img_item)\n",
        "    return img_items\n",
        "\n",
        "\n",
        "# 展示投影图\n",
        "def show_shadow(arr, direction='x'):\n",
        "    a_max = max(arr)\n",
        "    if direction == 'x':  # x轴方向的投影\n",
        "        a_shadow = np.zeros((a_max, len(arr)), dtype=int)\n",
        "        for i in range(0, len(arr)):\n",
        "            if arr[i] == 0:\n",
        "                continue\n",
        "            for j in range(0, arr[i]):\n",
        "                a_shadow[j][i] = 255\n",
        "    elif direction == 'y':  # y轴方向的投影\n",
        "        a_shadow = np.zeros((len(arr), a_max), dtype=int)\n",
        "        for i in range(0, len(arr)):\n",
        "            if arr[i] == 0:\n",
        "                continue\n",
        "            for j in range(0, arr[i]):\n",
        "                a_shadow[i][j] = 255\n",
        "\n",
        "    img_show_array(a_shadow)\n",
        "\n",
        "\n",
        "# 展示图片，路径展示方式\n",
        "def img_show_path(img_path):\n",
        "    pil_im = Image.open(img_path)\n",
        "    plt.imshow(pil_im)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 展示图片，数组展示方式\n",
        "def img_show_array(a):\n",
        "    plt.imshow(a)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 保存图片\n",
        "def save_imgs(dir_name, imgs):\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "\n",
        "    img_paths = []\n",
        "    for i in range(0, len(imgs)):\n",
        "        file_path = dir_name + '/part_' + str(i) + '.png'\n",
        "        cv2.imwrite(file_path, imgs[i])\n",
        "        img_paths.append(file_path)\n",
        "\n",
        "    return img_paths\n",
        "\n",
        "\n",
        "# %%\n",
        "def get_square_img(image):\n",
        "    x, y, w, h = cv2.boundingRect(image)\n",
        "    image = image[y:y + h, x:x + w]\n",
        "\n",
        "    max_size = 18\n",
        "    max_size_and_border = 24\n",
        "\n",
        "    if w > max_size or h > max_size:  # 有超过宽高的情况\n",
        "        if w >= h:  # 宽比高长，压缩宽\n",
        "            times = max_size / w\n",
        "            w = max_size\n",
        "            h = int(h * times)\n",
        "        else:  # 高比宽长，压缩高\n",
        "            times = max_size / h\n",
        "            h = max_size\n",
        "            w = int(w * times)\n",
        "        # 保存图片大小\n",
        "        image = cv2.resize(image, (w, h))\n",
        "\n",
        "    xw = image.shape[0]\n",
        "    xh = image.shape[1]\n",
        "\n",
        "    xwLeftNum = int((max_size_and_border - xw) / 2)\n",
        "    xwRightNum = (max_size_and_border - xw) - xwLeftNum\n",
        "\n",
        "    xhLeftNum = int((max_size_and_border - xh) / 2)\n",
        "    xhRightNum = (max_size_and_border - xh) - xhLeftNum\n",
        "\n",
        "    img_large = np.pad(image, ((xwLeftNum, xwRightNum), (xhLeftNum, xhRightNum)), 'constant', constant_values=(0, 0))\n",
        "\n",
        "    return img_large\n",
        "\n",
        "\n",
        "def divImg(img_path, save_file=False):\n",
        "    thresh = 200\n",
        "\n",
        "    img_o = cv2.imread(img_path, 1)\n",
        "\n",
        "    # 读入图片\n",
        "    img = cv2.imread(img_path, 0)\n",
        "    (img_h, img_w) = img.shape\n",
        "    # 二值化整个图，用于分行\n",
        "    ret, img_b = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # 计算投影，并截取整个图片的行\n",
        "    img_y_shadow_a = img_y_shadow(img_b)\n",
        "    row_mark_boxs = img2rows(img_y_shadow_a, img_w, img_h)\n",
        "    # 切行的图片，切的是原图\n",
        "    row_imgs = cut_img(img, row_mark_boxs)\n",
        "    all_mark_boxs = []\n",
        "    all_char_imgs = []\n",
        "    # ===============从行切块======================\n",
        "    for i in range(0, len(row_imgs)):\n",
        "        row_img = row_imgs[i]\n",
        "        (row_img_h, row_img_w) = row_img.shape\n",
        "        # 二值化一行的图，用于切块\n",
        "        ret, row_img_b = cv2.threshold(row_img, thresh, 255, cv2.THRESH_BINARY_INV)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        # 图像膨胀6次\n",
        "        row_img_b_d = cv2.dilate(row_img_b, kernel, iterations=6)\n",
        "        img_x_shadow_a = img_x_shadow(row_img_b_d)\n",
        "        block_mark_boxs = row2blocks(img_x_shadow_a, row_img_w, row_img_h)\n",
        "        row_char_boxs = []\n",
        "        row_char_imgs = []\n",
        "        # 切块的图，切的是原图\n",
        "        block_imgs = cut_img(row_img, block_mark_boxs)\n",
        "        if save_file:\n",
        "            b_imgs = save_imgs('imgs/cuts/row_' + str(i), block_imgs)  # 如果要保存切图\n",
        "            # print(b_imgs)\n",
        "        # =============从块切字====================\n",
        "        for j in range(0, len(block_imgs)):\n",
        "            block_img = block_imgs[j]\n",
        "            (block_img_h, block_img_w) = block_img.shape\n",
        "            # 二值化块,因为要切字符图片了\n",
        "            ret, block_img_b = cv2.threshold(block_img, thresh, 255, cv2.THRESH_BINARY_INV)\n",
        "            block_img_x_shadow_a = img_x_shadow(block_img_b)\n",
        "            row_top = row_mark_boxs[i][1]\n",
        "            block_left = block_mark_boxs[j][0]\n",
        "            char_mark_boxs, abs_char_mark_boxs = block2chars(block_img_x_shadow_a, block_img_w, block_img_h, row_top,\n",
        "                                                             block_left)\n",
        "            row_char_boxs.append(abs_char_mark_boxs)\n",
        "            # 切的是二值化的图\n",
        "            char_imgs = cut_img(block_img_b, char_mark_boxs, True)\n",
        "            row_char_imgs.append(char_imgs)\n",
        "            if save_file:\n",
        "                c_imgs = save_imgs('imgs/cuts/row_' + str(i) + '/blocks_' + str(j), char_imgs)  # 如果要保存切图\n",
        "                # print(c_imgs)\n",
        "        all_mark_boxs.append(row_char_boxs)\n",
        "        all_char_imgs.append(row_char_imgs)\n",
        "\n",
        "    return all_mark_boxs, all_char_imgs, img_o\n",
        "\n",
        "\n",
        "# 计算数值并返回结果\n",
        "def calculation(chars):\n",
        "    cstr = ''.join(chars)\n",
        "    c_r=''\n",
        "    result = ''\n",
        "\n",
        "    if (\"=\" in cstr):  # 有等号\n",
        "        str_arr = cstr.split('=')\n",
        "        c_str = str_arr[0]\n",
        "        r_str = str_arr[1]\n",
        "        c_str = c_str.replace(\"×\", \"*\")\n",
        "        c_str = c_str.replace(\"÷\", \"/\")\n",
        "        try:\n",
        "            c_r = int(eval(c_str))\n",
        "        except Exception as e:\n",
        "            print(\"Exception\", e)\n",
        "\n",
        "        if r_str == \"\":\n",
        "            result = c_r\n",
        "        else:\n",
        "            if str(c_r) == str(r_str):\n",
        "                result = \"√\"\n",
        "            else:\n",
        "                result = \"×\"\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# 绘制文本\n",
        "def cv2ImgAddText(img, text, left, top, textColor=(255, 0, 0), textSize=20):\n",
        "    if (isinstance(img, np.ndarray)):  # 判断是否OpenCV图片类型\n",
        "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # 创建一个可以在给定图像上绘图的对象\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # 字体的格式\n",
        "    fontStyle = ImageFont.truetype(\"Font\\行者笔记简.ttf\", textSize, encoding=\"utf-8\")\n",
        "    # 绘制文本\n",
        "    draw.text((left, top), text, textColor, font=fontStyle)\n",
        "    # 转换回OpenCV格式\n",
        "    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "\n",
        "# %%\n",
        "def main(path, save=False):\n",
        "    # 获取切图标注，切图图片，原图图图片\n",
        "    all_mark_boxs, all_char_imgs, img_o = divImg(path, save)\n",
        "    # 恢复模型，用于图片识别\n",
        "    model = modle1.create_custom_model((img_height, img_width, 1), 15)\n",
        "    model.load_weights('checkpoint/char_checkpoint.weights.h5')\n",
        "    class_name = np.load('checkpoint/class_name.npy')\n",
        "\n",
        "    # 遍历行\n",
        "    for i in range(0, len(all_char_imgs)):\n",
        "        row_imgs = all_char_imgs[i]\n",
        "        # 遍历块\n",
        "        for j in range(0, len(row_imgs)):\n",
        "            block_imgs = row_imgs[j]\n",
        "            block_imgs = np.array(block_imgs)\n",
        "            # 图片识别\n",
        "            results = modle1.predict(model, block_imgs, class_name)\n",
        "            print('recognize result:', results)\n",
        "            # 计算结果\n",
        "            result = calculation(results)\n",
        "            print('calculate result:', result)\n",
        "            # 获取块的标注坐标\n",
        "            block_mark = all_mark_boxs[i][j]\n",
        "            # 获取结果的坐标，写在块的最后一个字\n",
        "            answer_box = block_mark[-1]\n",
        "            # 计算最后一个字的位置\n",
        "            x = answer_box[2]\n",
        "            y = answer_box[3]\n",
        "            iw = answer_box[2] - answer_box[0]\n",
        "            ih = answer_box[3] - answer_box[1]\n",
        "            # 计算字体大小\n",
        "            textSize = max(iw, ih)\n",
        "            # 根据结果设置字体颜色\n",
        "            if str(result) == \"√\":\n",
        "                color = (0, 255, 0)\n",
        "            elif str(result) == \"×\":\n",
        "                color = (255, 0, 0)\n",
        "            else:\n",
        "                color = (192, 192, 192)\n",
        "            # 将结果写到原图上\n",
        "            img_o = cv2ImgAddText(img_o, str(result), answer_box[2], answer_box[1], color, textSize)\n",
        "    # 将写满结果的原图保存\n",
        "    cv2.imwrite('imgs/question_result.png', img_o)\n",
        "\n",
        "\n",
        "# %%\n",
        "if __name__ == '__main__':\n",
        "    t = time.time()\n",
        "    main('imgs/question.png', True)\n",
        "    print(f'all take time:{time.time() - t:.4f}s')\n",
        "# %%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Uvsk6vQiB96M",
        "outputId": "7ec7f1af-e12d-4785-ae45-3faea77bf1e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'modle1' has no attribute 'create_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-73c7664593b7>\u001b[0m in \u001b[0;36m<cell line: 366>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imgs/question.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'all take time:{time.time() - t:.4f}s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-73c7664593b7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(path, save)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mall_mark_boxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_char_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivImg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;31m# 恢复模型，用于图片识别\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodle1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint/char_checkpoint.weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint/class_name.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'modle1' has no attribute 'create_model'"
          ]
        }
      ]
    }
  ]
}